{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installing anvil\n!pip install anvil-uplink","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing neccessary packages\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers, models, optimizers, regularizers\nimport anvil.media\nimport anvil.server\nimport io\nfrom IPython.display import Image, display\nimport matplotlib.cm as cm\nfrom keras.preprocessing.image import load_img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loads trained model from memory\nsame_model = keras.models.load_model(\"my_model\")\nsame_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sets data path to dataset\ndata_path = '/kaggle/input/data256/Data256'\n\n# parameter constants\nbatch_size = 128\nimg_height = 256\nimg_width = 256\n\n# creates training dataset\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_path,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  color_mode='grayscale',\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\n# creates testing dataset\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n  data_path,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  color_mode='grayscale',\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\n# sets class names\nclass_names = train_ds.class_names\nnum_classes = len(class_names)\nprint(class_names)\n\n# applies prefetch transformation input pipeline\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n# normalizes data pixel values between 0-1 and creates data batches\nnormalization_layer = layers.Rescaling(1./255)\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nnormalized_test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\ntest_image_batch, test_labels_batch = next(iter(normalized_test_ds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creates data augmentation layer\ndata_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(256,\n                                  256,\n                                  1)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)\n\n# creates CNN model\nmodel = Sequential([\n  data_augmentation,\n  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256, 1)),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(128, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(256, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(512, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(512, activation='relu'),\n  layers.Dense(num_classes, name=\"outputs\")\n])\n\n# compiles CNN model\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trains model for 100 epochs\nepochs = 100\nhistory = model.fit(\n  normalized_train_ds,\n  epochs = epochs,\n  validation_data = normalized_test_ds \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluates model accuracy on testing dataset\nmodel.evaluate(normalized_test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# connects to anvil website server\nanvil.server.connect(\"server_LQLZDGGDEATEV563AGBYES73-GEMOTF2RRYNYHUIC\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# returns predictions of model on image\n@anvil.server.callable\ndef predict_image(img1):\n    probabilities = [0, 0, 0]\n    with anvil.media.TempFile(img1) as i:\n        img2 = tf.keras.utils.load_img(i)\n    img_color = img2.resize((256,256)) \n    img = img_color.convert(\"L\")\n    img_array = tf.keras.utils.img_to_array(img)\n    img_normalized = img_array.astype(np.float) / 255\n    img_batch = tf.expand_dims(img_normalized, 0)\n    predictions = same_model.predict(img_batch)\n    predictions_final = tf.nn.softmax(predictions[0])\n    for i in range(3):\n        probabilities[i] = float(predictions_final[i])  \n    prediction = class_names[np.argmax(predictions_final)]\n\n    return probabilities, prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converts input image to JPEG\ndef img_to_media_obj(img):\n  img_byte_arr = io.BytesIO()\n  img.save(img_byte_arr, format='JPEG')\n  img_byte_arr = img_byte_arr.getvalue()\n  media_obj = anvil.BlobMedia(content_type=\"image/jpeg\", content=img_byte_arr)\n  return media_obj","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}